{"cells":[{"cell_type":"markdown","metadata":{"id":"592U6lXs3d2t"},"source":["# Week2_2 Assignment\n","\n","## [BASIC](#Basic) \n","- \"네이버 영화 감성 분류\" 데이터를 불러와 `pandas` 라이브러리를 사용해 **전처리** 할 수 있다.\n","- 적은 데이터로도 높은 성능을 내기 위해, pre-trained `BERT` 모델 위에 1개의 hidden layer를 쌓아 **fine-tuning**할 수 있다.\n","\n","## [CHALLENGE](#Challenge)\n","- 토큰화된 학습 데이터를 배치 단위로 갖는 **traindata iterator**를 구현할 수 있다. \n","\n","## [ADVANCED](#Advanced)\n","- **loss와 optimizer 함수**를 사용할 수 있다. \n","- traindata iterator를 for loop 돌며 **fine-tuning** 할 수 있다.\n","- fine-tuning의 2가지 방법론을 비교할 수 있다. \n","  - BERT 파라미터를 **freeze** 한 채 fine-tuning (Vision에서 주로 사용하는 방법론)\n","  - BERT 파라미터를 **unfreeze** 한 채 fine-tuning (NLP에서 주로 사용하는 방법론)\n","\n","\n","### Reference\n","- [huggingface 한국어 오픈소스 모델](https://huggingface.co/models?language=ko&sort=downloads&search=bert)\n","- [transformer BertForSequenceClassification 소스 코드](https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/bert/modeling_bert.py#L1501)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KSX-wQA1RD1h","executionInfo":{"status":"ok","timestamp":1648120205794,"user_tz":-540,"elapsed":7486,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["import os\n","import sys\n","import pandas as pd\n","import numpy as np \n","import torch\n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4Reyt-HvLnJv","executionInfo":{"status":"ok","timestamp":1648120205795,"user_tz":-540,"elapsed":9,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["# seed\n","seed = 7777\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gUR6vb3L3d2u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c61d3775-43cf-4976-bb99-ca9967bf4324","executionInfo":{"status":"ok","timestamp":1648120205795,"user_tz":-540,"elapsed":8,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["# available GPUs : 1\n","GPU name : Tesla P100-PCIE-16GB\n","cuda\n"]}],"source":["# device type\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print(f\"# available GPUs : {torch.cuda.device_count()}\")\n","  print(f\"GPU name : {torch.cuda.get_device_name()}\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"c93M8XmjLnJw"},"source":["## Basic"]},{"cell_type":"markdown","metadata":{"id":"0REKl4EvT9G1"},"source":["### 데이터 다운로드 및 DataFrame 형태로 불러오기\n","- 내 구글 드라이브에 데이터를 다운받은 후 코랩에 드라이브를 마운트하면 데이터를 영구적으로 사용할 수 있음.\n","- [네이버영화감성분류](https://github.com/e9t/nsmc)\n","  - trainset: 150,000 \n","  - testset: 50,000 "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lEWUggR1R9rS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16d645aa-4fe1-4944-db69-55118c9bd7ee","executionInfo":{"status":"ok","timestamp":1648120222533,"user_tz":-540,"elapsed":16744,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rov1s8IxSLqy","executionInfo":{"status":"ok","timestamp":1648119531864,"user_tz":-540,"elapsed":17,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["#cd \"/content/drive/MyDrive/여기에 파일 경로를 입력\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OjPGnbEjVYmj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8c48186-e8aa-4997-8f95-026bbd381db4","executionInfo":{"status":"ok","timestamp":1648120244050,"user_tz":-540,"elapsed":6888,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 18.69 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}],"source":["# 데이터 다운로드\n","!git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SueG9v14YbgF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"644c6a3f-625f-4790-cf39-68689d8e759e","executionInfo":{"status":"ok","timestamp":1648120246077,"user_tz":-540,"elapsed":295,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["My current directory : /content\n"]}],"source":["_CUR_DIR = os.path.abspath(os.curdir)\n","print(f\"My current directory : {_CUR_DIR}\")\n","_DATA_DIR = os.path.join(_CUR_DIR, \"nsmc\")"]},{"cell_type":"code","source":["with open ('/content/nsmc/ratings_train.txt') as f :\n","  lines  = f.readlines()\n","\n","for line in lines[:3] :\n","  print(len(line.split(',')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1ANEEwt-76_","outputId":"58919757-432c-4d01-db22-49fa39d2c3f5","executionInfo":{"status":"ok","timestamp":1648119537406,"user_tz":-540,"elapsed":8,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n","1\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9J6KQ8dzaHBi","executionInfo":{"status":"ok","timestamp":1648120249431,"user_tz":-540,"elapsed":407,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["# nsmc/ratings_train.txt를 DataFrame 형태로 불러오기\n","df = pd.read_csv('/content/nsmc/ratings_train.txt',sep = '\\t')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3cUsoBEPahlo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6e12672-56bd-4f42-fcc9-c205d094400e","executionInfo":{"status":"ok","timestamp":1648120252514,"user_tz":-540,"elapsed":264,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150000, 3)"]},"metadata":{},"execution_count":10}],"source":["# 데이터 크기 확인\n","df.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Ic3k9CORaXzM","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"03e5b6f1-4c3d-43e7-dcc4-52676595ff01","executionInfo":{"status":"ok","timestamp":1648120253669,"user_tz":-540,"elapsed":29,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"],"text/html":["\n","  <div id=\"df-9e29d415-b684-4cfc-be79-cd7395755970\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e29d415-b684-4cfc-be79-cd7395755970')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e29d415-b684-4cfc-be79-cd7395755970 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e29d415-b684-4cfc-be79-cd7395755970');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["# 데이터 일부 확인\n","df.head()"]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTvzOduU_78t","outputId":"e1bed30a-99d3-4f2a-a9b6-ca5118b754d3","executionInfo":{"status":"ok","timestamp":1648120256126,"user_tz":-540,"elapsed":243,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150000 entries, 0 to 149999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count   Dtype \n","---  ------    --------------   ----- \n"," 0   id        150000 non-null  int64 \n"," 1   document  149995 non-null  object\n"," 2   label     150000 non-null  int64 \n","dtypes: int64(2), object(1)\n","memory usage: 3.4+ MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"JA1F0tHWLnJz"},"source":["### 데이터 결측치 제거 및 데이터 수 줄이기 \n","- 학습 데이터 수는 150,000개로 매우 많은 양이다. 하지만 우리가 실생활에서 마주할 데이터는 이렇게 많지 않다. 이 때 유용하게 사용되는 것이 **fine-tuning** 학습 방법이다.   \n","- Fine-tuning은 단어의 의미를 이미 충분히 학습한 모델 (여기서는 **BERT**)을 가져와 그 위에 추가적인 Nueral Network 레이어를 쌓은 후 학습하는 방법론이다. 이미 BERT가 단어의 의미를 충분히 학습했기 때문에 **적은 데이터**로 학습해도 우수한 성능을 낼 수 있다는 장점이 있다. \n","- **데이터의 label의 비율이 5:5를 유지하면서** 학습 데이터 수를 150,000개에서 1,000개로 줄이\b는 함수 `label_evenly_balanced_dataset_sampler`를 구현하라.\n","  - 함수 정의 \n","    - 입력 매개변수\n","      - df : DataFrame\n","      - n_sample : df에서 샘플링할 row의 개수 (여기서는 1000개로 정의한다)\n","    - 조건\n","      - label의 비율이 5:5를 유지할 수 있도록 샘플링한다.\n","    - 반환값\n","      - row의 개수가 1000개인 dataframe"]},{"cell_type":"code","source":["df['label'].value_counts(dropna = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D25dSrRhADrP","outputId":"74c2f970-b3ac-4919-9075-114f2e021d28","executionInfo":{"status":"ok","timestamp":1648120269443,"user_tz":-540,"elapsed":258,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    75173\n","1    74827\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-gWi537COpw","outputId":"8070b619-12e1-463e-8f6c-55a91ecbe29d","executionInfo":{"status":"ok","timestamp":1648120271000,"user_tz":-540,"elapsed":18,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id          0\n","document    5\n","label       0\n","dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Lh9BSiSeMms7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d2e3d94-117f-4246-f37d-a8689d0bc981","executionInfo":{"status":"ok","timestamp":1648120272412,"user_tz":-540,"elapsed":285,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["id          0\n","document    0\n","label       0\n","dtype: int64"]},"metadata":{},"execution_count":15}],"source":["# df에서 결측치 (na 값) 제거\n","\n","df = df.dropna()\n","df.isna().sum()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ommF5KH4akCJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e710177-ed75-402e-ed33-45da93f6fd30","executionInfo":{"status":"ok","timestamp":1648120298516,"user_tz":-540,"elapsed":258,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    75170\n","1    74825\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":17}],"source":["# label별 데이터 수 확인\n","# pandas의 value_counts 함수 활용\n","# 0 -> 부정 1 -> 긍정\n","\n","df.label.value_counts()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_ii06wCsc107","executionInfo":{"status":"ok","timestamp":1648120302883,"user_tz":-540,"elapsed":422,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["# 학습 데이터 샘플 개수 설정\n","\n","n_sample = 1000"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Hrkhl69Dc-kr","executionInfo":{"status":"ok","timestamp":1648120320236,"user_tz":-540,"elapsed":251,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["# 샘플링 함수 구현\n","# random 모듈에서 제공되는 함수 활용\n","# input: 학습 데이터 샘플 개수\n","# output: 샘플링 데이터\n","\n","def label_evenly_balanced_dataset_sampler(df, sample_size):\n","  \"\"\"\n","  데이터 프레임의을 sample_size만큼 임의 추출해 새로운 데이터 프레임을 생성.\n","  이 때, \"label\"열의 값들이 동일한 비율을 갖도록(5:5) 할 것.\n","  \"\"\"\n","\n","  df = df.reset_index(drop=True) # Index로 iloc하기 위해서는 df의 index를 초기화해줘야 함\n","  \n","  neg_idx = df.loc[df.label==0].index\n","  neg_idx_sample = random.sample(neg_idx.to_list(), k=int(sample_size/2))\n","\n","  pos_idx = df.loc[df.label==1].index\n","  pos_idx_sample = random.sample(pos_idx.to_list(), k=int(sample_size/2))\n","\n","  return df.iloc[neg_idx_sample+pos_idx_sample]"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"hXLT6tAdaA34","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94f5fba0-16a5-4955-c770-60e9f6fed38a","executionInfo":{"status":"ok","timestamp":1648120321806,"user_tz":-540,"elapsed":444,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    500\n","1    500\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":20}],"source":["# 검증\n","sample_df = label_evenly_balanced_dataset_sampler(df, n_sample)\n","sample_df.label.value_counts()"]},{"cell_type":"code","source":["sample_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_H9DGuAv4rE","outputId":"832537c5-f0b3-4812-8054-1c8f04a60182","executionInfo":{"status":"ok","timestamp":1648120323935,"user_tz":-540,"elapsed":513,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1000 entries, 36416 to 82988\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   id        1000 non-null   int64 \n"," 1   document  1000 non-null   object\n"," 2   label     1000 non-null   int64 \n","dtypes: int64(2), object(1)\n","memory usage: 31.2+ KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"cLNUjgawLnJ1"},"source":["### CustomClassifier 클래스 구현\n","<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_bertclf.png?raw=true\" width=400>\n","\n","- 그림과 같이 사전 학습(pre-trained)된 `BERT` 모델을 불러와 그 위에 **1 hidden layer**와 **binary classifier layer**를 쌓아 fine-tunning 모델을 생성할 것이다.    \n","---\n","- hidden layer 1개와 output layer(binary classifier layer)를 갖는 `CustomClassifier` 클래스를 구현하라.\n","- 클래스 정의\n","  - 생성자 입력 매개변수\n","    - `hidden_size` : BERT의 embedding size\n","    - `n_label` : class(label) 개수\n","  - 생성자에서 생성할 변수\n","    - `bert` : BERT 모델 인스턴스 \n","    - `classifier` : 1 hidden layer + relu +  dropout + classifier layer를 stack한 `nn.Sequential` 모델\n","      - 첫번재 히든 레이어 (첫번째 `nn.Linear`)\n","        - input: BERT의 마지막 layer의 1번재 token ([CLS] 토큰) (shape: `hidden_size`)\n","        - output: (shape: `linear_layer_hidden_size`)\n","      - 아웃풋 레이어 (두번째 `nn.Linear`)\n","        - input: 첫번째 히든 레이어의 아웃풋 (shape: `linear_layer_hidden_size`)\n","        - output: target/label의 개수 (shape:2)\n","  - 메소드\n","    - `forward()`\n","      - BERT output에서 마지막 레이어의 첫번째 토큰 ('[CLS]')의 embedding을 가져와 `self.classifier`에 입력해 아웃풋으로 logits를 출력함.\n","  - 주의 사항\n","    - `CustomClassifier` 클래스는 부모 클래스로 `nn.Module`을 상속 받는다.\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"U0WbqVv62Zvy","executionInfo":{"status":"ok","timestamp":1648120430778,"user_tz":-540,"elapsed":283,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Im98H4-U1eQQ","executionInfo":{"status":"ok","timestamp":1648120509934,"user_tz":-540,"elapsed":250,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["# classifier 구현\n","class CustomClassifier(nn.Module):\n","\n","    def __init__(self, hidden_size: int, n_label: int):\n","        super(CustomClassifier, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n","\n","        dropout_rate = 0.1\n","        linear_layer_hidden_size = 32\n","\n","        self.classifier = nn.Sequential(\n","        nn.Linear(hidden_size, linear_layer_hidden_size),\n","        nn.ReLU(),\n","        nn.Dropout(dropout_rate),\n","        nn.Linear(linear_layer_hidden_size, n_label)\n","        )\n","\n","    \n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","        )\n","        \n","        # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n","        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n","        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n","\n","        logits = self.classifier(cls_token_last_hidden_states)\n","\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"9x7PU1t1LnJ1"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"YXesCG5TLnJ1"},"source":["### 학습 데이터를 배치 단위로 저장하는 이터레이터 함수 `data_iterator` 구현\n","- 데이터 프레임을 입력 받아 text를 \b토큰 id로 변환하고 label은 텐서로 변환해 배치만큼 잘라 (input, \btarget) 튜플 형태의 이터레이터를 생성하는 `data_iterator` 함수를 구현하라.\n","- 함수 정의 \n","  - 입력 매개변수\n","    - `input_column` : text 데이터 column 명\n","    - `target_column` : label 데이터 column 명\n","    -  `batch_size` : 배치 사이즈\n","  - 조건\n","    - 함수는 다음을 수행해야 함 \n","      - 데이터 프레임 랜덤 셔플링\n","      - `tokenizer_bert`로 text를 token_id로 변환 + 텐서화 \n","      - target(label)을 텐서화\n","  - 반환값 \n","    - (input, target) 튜플 형태의 이터레이터를 반환"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"q-tJERGI4Fzk","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3113a214-8fbf-4340-88f9-14906d3c9a00","executionInfo":{"status":"ok","timestamp":1648120524512,"user_tz":-540,"elapsed":9939,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.1 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"JlcYCOyW3d2t","executionInfo":{"status":"ok","timestamp":1648120524512,"user_tz":-540,"elapsed":6,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["from transformers import BertTokenizer, BertModel"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"C_U_c-Mf3d2t","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["4b288738bf0d4343b4d9aa7c24a61d2b","a3262bbb3c5445ec8a359044397fecaa","cbc5e27d7bfb4ba1857d93300efaa012","7d52b52e33db4113914c05c82d8a6069","1810b77004214b9bad26deab2b56430e","f2075dc9a6754369981fa5da91a7750d","feccdbd55a4c4d6fb495d88a697811f0","ac2fd9cce511436386da544e2b9910c5","ebb458030d54432f819abb34f3d1ba34","df51dc71db7d48539b845e8633f1c09d","29a67b25ec064dbb88081fbbcfdc674f","982478c932194adda986f23a90b7270a","287f3e7cd0634fd783a3c7f7673d63da","fb54ff5e91d74aef90dd24645195cb3a","36686e9c441245039a33575493943ada","5c490849ea384dfe8d3c9651b1b7a0f0","c250e0f70a1b49e3b05b1db9e75d422a","91483c64ef844402bc7b7d97c1989f22","7496a6a38df447469802185c0aed7f80","feb7f8898dd74d9ba4a237e385f99bdc","b7439bd51a5546389fb55dc3c6537946","2ad25fd1e4e849198f4dac8bf3f87efd","f4ab7ea552844657b7a5083ccf99139b","49210d3ee9d3494d94d2cb5d28594486","ab1d4aff729c4db28f7309c53c0de157","efc5afb3bef94a01ad1c8ba6b9ac4eed","8993bc5eb2fb4293a8bd27b3ac49c82d","5698537832ac4d77856519666d9eadea","35cfc65801a04df3845bf4b894085baa","7490f1a811724ec4bf8085896eec5c65","b99184549f65427fac1ef7d4e5bc50ca","dcbf80ae4374428abf4fa83bcc652be8","f8486688d5974f4a8c873aad4056afa6","a11e7de3894e4c84a38a7bb51a0cf9c0","19b3f2fc6c4547de8e9b15e32761453f","3573c8c2348f4c2c96071a16b0d629fa","1e94399593464ba79d0a286f0da9d7b3","f0ee73bd8b154d56b604e77c0a84d3da","15ab094fbd0c4ecb9e47606d5afd0346","b669050fc39e48ffbe7d7661139e1fd7","5fc4505367b84ffabd4af12508c55deb","7612eae596a0443682c4b0856dcd4823","651cea257f494d98812b3aeec8425b89","87b13dc7f26d4366a03cd44ed5ce0bba"]},"outputId":"93bbea10-5018-4431-cb06-8ca2fcaa6012","executionInfo":{"status":"ok","timestamp":1648120526300,"user_tz":-540,"elapsed":1794,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b288738bf0d4343b4d9aa7c24a61d2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"982478c932194adda986f23a90b7270a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4ab7ea552844657b7a5083ccf99139b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11e7de3894e4c84a38a7bb51a0cf9c0"}},"metadata":{}}],"source":["tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\") # lower-cased version"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"p2VnIY-ALnJ2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"abbd29e7-16af-4d0d-94bb-64c25af2d944","executionInfo":{"status":"ok","timestamp":1648120534368,"user_tz":-540,"elapsed":272,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence: 나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.\n","\n","Tokenized Sentence: {'input_ids': tensor([[    2,   717,  4647,   831,  2604,  2069,  4869,  2205, 18246,  3926,\n","          2088,  1170, 13964,  9379,   831,  2604,  2052,  9822, 23677,    18,\n","            18,    18,   831,  2604,  2052,  3760,  5429,  2507,  2053,    18,\n","             3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1]])}\n"]}],"source":["# 토크나이징 예시 (1개의 문장)\n","\n","# 1. string type의 문장을 가져옴\n","ex_sent = sample_df.document.iloc[0]\n","print(f\"Original Sentence: {ex_sent}\\n\")\n","\n","# 2. 문장을 토크나이즈 함. 이 때, 특수 토큰 (\"[CLS]\", \"[SPE]\")을 자동으로 추가하고 pytorch의 tensor형태로 변환해 반환함\n","tensor_sent = tokenizer_bert(\n","    ex_sent,\n","    add_special_tokens=True, # 문장의 앞에 문장 시작을 알리는 \"[CLS]\"토큰, 문장의 끝에 문장 끝을 알리는 \"[SPE]\"토큰을 자동으로 추가\n","    return_tensors='pt' # pytorch tensor로 반환할 것\n",")\n","print(f\"Tokenized Sentence: {tensor_sent}\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"rtXP_wRFLnJ2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d9be8a5-0bef-46eb-acb6-cb0691f6a3dc","executionInfo":{"status":"ok","timestamp":1648120547531,"user_tz":-540,"elapsed":266,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence 1: 나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.\n","Original Sentence 2: 현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...\n","\n","Tokenized Sentence list: {'input_ids': tensor([[    2,   717,  4647,   831,  2604,  2069,  4869,  2205, 18246,  3926,\n","          2088,  1170, 13964,  9379,   831,  2604,  2052,  9822, 23677,    18,\n","            18,    18,   831,  2604,  2052,  3760,  5429,  2507,  2053,    18,\n","             3],\n","        [    2,  1919,  2562,  2052,  7750,  2474,  2052,  2359,  6076,  1560,\n","          2886,  2918, 13964,    18,    18,  6354, 22023,  2119,  1556,  7436,\n","          2205,  2318,    18,    18,    18,     3,     0,     0,     0,     0,\n","             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 0, 0, 0, 0, 0]])}\n"]}],"source":["# 토크나이징 예시 (2개의 문장)\n","\n","# 1. 2개의 문장을 가진 list 생성\n","ex_sent_list = list(sample_df.document.iloc[:2].values)\n","for i, sent in enumerate(ex_sent_list):\n","    print(f\"Original Sentence {i+1}: {sent}\")\n","\n","# 2. 문장 리스트를 토크나이즈 함. 이 때, 리스트 내 문장들의 토큰 길이가 동일할 수 있도록 가장 긴 문장을 기준으로 부족한 위치에 \"[PAD]\" 토큰을 추가\n","tensor_sent_list = tokenizer_bert(\n","    ex_sent_list,\n","    add_special_tokens=True,\n","    return_tensors='pt',\n","    padding=\"longest\" # 가장 긴 문장을 기준으로 token개수를 맞춤. 모자란 토큰 위치는 \"[PAD]\" 토큰을 추가\n",")\n","\n","print(f\"\\nTokenized Sentence list: {tensor_sent_list}\")\n","\n","# 토크나이즈 된 두 문장의 길이가 동일함을 검증\n","assert tensor_sent_list['input_ids'][0].shape == tensor_sent_list['input_ids'][1].shape "]},{"cell_type":"code","execution_count":29,"metadata":{"id":"tR22xs-xf1QH","executionInfo":{"status":"ok","timestamp":1648120592829,"user_tz":-540,"elapsed":348,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["def data_iterator(df, input_column, target_column, batch_size):\n","  \"\"\"\n","  데이터 프레임을 셔플한 후 \n","  데이터 프레임의 input_column을 batch_size만큼 잘라 토크나이즈 + 텐서화하고, target_column을 batch_size만큼 잘라 텐서화 하여\n","  (input, output) 튜플 형태의 이터레이터를 생성\n","  \"\"\"\n","\n","  global tokenizer_bert\n","\n","  # 1. 데이터 프레임 셔플\n","  df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n","  \n","  # 2. 이터레이터 생성\n","  for idx in range(0, df.shape[0], batch_size):\n","      batch_df = df.iloc[idx: idx+batch_size]\n","      \n","      tensorized_input = tokenizer_bert(\n","          batch_df[input_column].to_list(),\n","          add_special_tokens=True,\n","          padding = \"longest\",\n","          return_tensors='pt'\n","      )\n","      \n","      tensorized_target = torch.tensor(\n","          batch_df[target_column].to_list()\n","      )\n","      \n","      yield tensorized_input, tensorized_target"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"zTlAV0hqILmc","executionInfo":{"status":"ok","timestamp":1648120603085,"user_tz":-540,"elapsed":259,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["batch_size=32\n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"P9VNAMchf1QI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6f16bd4-3ef7-46f9-d029-4dfdba232964","executionInfo":{"status":"ok","timestamp":1648120604488,"user_tz":-540,"elapsed":427,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'input_ids': tensor([[    2, 27740,  2899,  ...,     0,     0,     0],\n","         [    2, 24935, 29422,  ...,     0,     0,     0],\n","         [    2,  4380,  3785,  ...,     0,     0,     0],\n","         ...,\n","         [    2,  1453,    16,  ...,     0,     0,     0],\n","         [    2,  3771,  4229,  ...,     0,     0,     0],\n","         [    2,  3833, 15351,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]])},\n"," tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n","         1, 0, 1, 0, 1, 1, 0, 0]))"]},"metadata":{},"execution_count":31}],"source":["next(train_iterator)"]},{"cell_type":"markdown","metadata":{"id":"Cqnp2Q6ZLnJ2"},"source":["## Advanced"]},{"cell_type":"markdown","metadata":{"id":"cQVTqAUxLnJ2"},"source":["### `data_iterator` 함수로 생성한 이터레이터를 for loop 돌면서 배치 단위의 데이터를 모델에 학습하는 `train()` 함수 구현\n","- 함수 정의\n","  - 입력 매개변수\n","    - `model` : BERT + 1 hidden layer classifier 모델\n","    - `data_iterator` : train data iterator\n","- Reference\n","  - [Loss: CrossEntropyLoss official document](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n","  - [Optimizer: AdamW official document](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"-sE7xjYcRD1p","executionInfo":{"status":"ok","timestamp":1648120609541,"user_tz":-540,"elapsed":264,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["from torch.optim import AdamW\n","from torch.nn import CrossEntropyLoss"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ZvY5rxDKHQAp","executionInfo":{"status":"ok","timestamp":1648120616942,"user_tz":-540,"elapsed":241,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["def train(model, data_iterator):\n","\n","      # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n","      total_loss, batch_loss, batch_count = 0,0,0\n","      \n","      # model을 train 모드로 설정 & device 할당\n","      model.train()\n","      model.to(device)\n","      \n","      # data iterator를 돌면서 하나씩 학습\n","      for step, batch in enumerate(data_iterator):\n","          batch_count+=1\n","          \n","          # tensor 연산 전, 각 tensor에 device 할당\n","          batch = tuple(item.to(device) for item in batch)\n","          \n","          batch_input, batch_label = batch\n","          \n","          # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n","          model.zero_grad()\n","          \n","          # forward\n","          logits = model(**batch_input)\n","          \n","          # loss\n","          loss = loss_fct(logits, batch_label)\n","          batch_loss += loss.item()\n","          total_loss += loss.item()\n","          \n","          # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n","          loss.backward()\n","          \n","          # optimizer 업데이트\n","          optimizer.step()\n","          \n","          # 배치 10개씩 처리할 때마다 평균 loss를 출력\n","          if (step % 10 == 0 and step != 0):\n","              print(f\"Step : {step}, Avg Loss : {batch_loss / batch_count:.4f}\")\n","              \n","              # 변수 초기화 \n","              batch_loss, batch_count = 0,0\n","      \n","      print(f\"Mean Loss : {total_loss/(step+1):.4f}\")\n","      print(\"Train Finished\")"]},{"cell_type":"markdown","metadata":{"id":"OEYo8z9RLnJ2"},"source":["### 지금까지 구현한 함수와 클래스를 모두 불러와 `train()` 함수를 실행하자\n","- fine-tuning 모델 클래스 (`CustomClassifier`)\n","    - hidden_size = 768\n","    - n_label = 2\n","- 데이터 이터레이터 함수 (`data_iterator`)\n","    - batch_size = 32\n","- loss \n","    - `CrossEntropyLoss()`\n","- optimizer\n","    - optimizer는 loss(오차)를 상쇄하기 위해 파라미터를 업데이트 하는 과정\n","    - `optimizer.step()` 시 파라미터가 업데이트 됨 \n","    - lr = 2e-5\n","- Reference\n","  - [Optimizer 종류 설명 한국어 블로그 ](https://ganghee-lee.tistory.com/24)\n","    "]},{"cell_type":"code","source":["# 학습 시작\n","# 모델\n","model = CustomClassifier(hidden_size=768, n_label=2)\n","\n","# 데이터 이터레이터\n","batch_size = 32\n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n","\n","# 로스 및 옵티마이저\n","loss_fct = CrossEntropyLoss()\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=2e-5,\n","    eps=1e-8\n",")\n","\n","train(model, train_iterator)"],"metadata":{"id":"KwMPVoSyYnZW","colab":{"base_uri":"https://localhost:8080/","height":215,"referenced_widgets":["37a668c29667400aabe2aaf65876a612","e458d56fbfe7409c9d2dc6ebbab4f40a","2caff93ce43f41d58f5c035be02e2fef","82d112ec515a4fc79d23f712e5bb68a5","5132c6702862499d9bf81741c9d31839","c8237c8a0e124775a91de8caf25251f3","b40af997745c4d809e1e856bf1508a01","3e1f6485880744099bf40a9a8be7a6a9","03eb745c5e2a438ea87851863c2c2b56","552aaeabb3cb4ef7ba66664dd23590a5","30e3050518a0455ca8fded0e43df3356"]},"executionInfo":{"status":"ok","timestamp":1648120668241,"user_tz":-540,"elapsed":33366,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}},"outputId":"f2538cdb-9fed-4575-f227-f6dd7a49c287"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37a668c29667400aabe2aaf65876a612"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Step : 10, Avg Loss : 0.6587\n","Step : 20, Avg Loss : 0.5362\n","Step : 30, Avg Loss : 0.4196\n","Mean Loss : 0.5318\n","Train Finished\n"]}]},{"cell_type":"markdown","metadata":{"id":"37UbAkh7LnJ3"},"source":["## fine-tuning 2가지 방법론 비교\n","- pre-trained BERT 모델 파라미터를 **freeze**한 채 학습하라\n","    - BERT의 파라미터의 `requires_grad` 값을 `False`로 바꾸면, 학습 시 BERT의 파라미터는 미분이 계산되지도, 업데이트 되지도 않는다. \n","    - 이렇게 특정 모델의 파라미터가 업데이트 하지 못하도록 설정하는 것을 **freeze**라고 한다. \n","    - BERT 파라미터를 freeze시킨 채 학습을 진행해보자. 이럴 경우, 우리가 직접 쌓은 fine-tuning layer의 파라미터만 업데이트 된다. \n","- **unfreeze**와 **freeze** 모델의 성능을 비교해 보자. 어떤 방식이 더 우수한가?\n","\n","    "]},{"cell_type":"code","execution_count":35,"metadata":{"id":"Ld260K3YLnJ3","executionInfo":{"status":"ok","timestamp":1648120684937,"user_tz":-540,"elapsed":254,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}}},"outputs":[],"source":["class CustomClassifierFreezed(nn.Module):\n","\n","    def __init__(self, hidden_size: int, n_label: int):\n","        super(CustomClassifierFreezed, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n","        # freeze BERT parameter\n","        # BERT의 파라미터는 고정값으로 두고 BERT 위에 씌운 linear layer의 파라미터만 학습하려고 한다. \n","        # 이 경우, BERT의 파라미터의 'requires_grad' 값을 False로 변경해줘야 학습 시 해당 파라미터의 미분값이 계산되지 않는다.\n","        for param in self.bert.parameters():\n","            param.requires_grad = False\n","\n","        dropout_rate = 0.1\n","        linear_layer_hidden_size = 32\n","\n","        self.classifier = nn.Sequential(\n","        nn.Linear(hidden_size, linear_layer_hidden_size),\n","        nn.ReLU(),\n","        nn.Dropout(dropout_rate),\n","        nn.Linear(linear_layer_hidden_size, n_label)\n","        )\n","\n","    \n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","        )\n","        \n","        # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n","        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n","        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n","\n","        logits = self.classifier(cls_token_last_hidden_states)\n","\n","        return logits"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"2ClEEHB6F6LW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648120691817,"user_tz":-540,"elapsed":2411,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}},"outputId":"5db601c2-d42c-400b-b13c-96d11c5c0825"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# freeze 모델\n","# model을 제외한 설정값은 \b위에서 실행한 unfreeze 모델과 동일\n","model = CustomClassifierFreezed(hidden_size=768, n_label=2)\n","\n","# 데이터 이터레이터\n","batch_size = 32\n","train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n","\n","# 로스 및 옵티마이저\n","loss_fct = CrossEntropyLoss()\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=2e-5,\n","    eps=1e-8\n",")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"hqcPcWZeLnJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648120697893,"user_tz":-540,"elapsed":3169,"user":{"displayName":"sw","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08713986034663086241"}},"outputId":"06ace8c6-d19c-4e19-81da-a7e15c204e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Step : 10, Avg Loss : 0.7237\n","Step : 20, Avg Loss : 0.7121\n","Step : 30, Avg Loss : 0.7166\n","Mean Loss : 0.7159\n","Train Finished\n"]}],"source":["# 학습 시작\n","train(model, train_iterator)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Week2_2_assignment.ipynb","provenance":[]},"kernelspec":{"display_name":"torch","language":"python","name":"torch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4b288738bf0d4343b4d9aa7c24a61d2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3262bbb3c5445ec8a359044397fecaa","IPY_MODEL_cbc5e27d7bfb4ba1857d93300efaa012","IPY_MODEL_7d52b52e33db4113914c05c82d8a6069"],"layout":"IPY_MODEL_1810b77004214b9bad26deab2b56430e"}},"a3262bbb3c5445ec8a359044397fecaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2075dc9a6754369981fa5da91a7750d","placeholder":"​","style":"IPY_MODEL_feccdbd55a4c4d6fb495d88a697811f0","value":"Downloading: 100%"}},"cbc5e27d7bfb4ba1857d93300efaa012":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac2fd9cce511436386da544e2b9910c5","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebb458030d54432f819abb34f3d1ba34","value":248477}},"7d52b52e33db4113914c05c82d8a6069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df51dc71db7d48539b845e8633f1c09d","placeholder":"​","style":"IPY_MODEL_29a67b25ec064dbb88081fbbcfdc674f","value":" 243k/243k [00:00&lt;00:00, 1.54MB/s]"}},"1810b77004214b9bad26deab2b56430e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2075dc9a6754369981fa5da91a7750d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feccdbd55a4c4d6fb495d88a697811f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac2fd9cce511436386da544e2b9910c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebb458030d54432f819abb34f3d1ba34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df51dc71db7d48539b845e8633f1c09d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29a67b25ec064dbb88081fbbcfdc674f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"982478c932194adda986f23a90b7270a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_287f3e7cd0634fd783a3c7f7673d63da","IPY_MODEL_fb54ff5e91d74aef90dd24645195cb3a","IPY_MODEL_36686e9c441245039a33575493943ada"],"layout":"IPY_MODEL_5c490849ea384dfe8d3c9651b1b7a0f0"}},"287f3e7cd0634fd783a3c7f7673d63da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c250e0f70a1b49e3b05b1db9e75d422a","placeholder":"​","style":"IPY_MODEL_91483c64ef844402bc7b7d97c1989f22","value":"Downloading: 100%"}},"fb54ff5e91d74aef90dd24645195cb3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7496a6a38df447469802185c0aed7f80","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_feb7f8898dd74d9ba4a237e385f99bdc","value":125}},"36686e9c441245039a33575493943ada":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7439bd51a5546389fb55dc3c6537946","placeholder":"​","style":"IPY_MODEL_2ad25fd1e4e849198f4dac8bf3f87efd","value":" 125/125 [00:00&lt;00:00, 3.15kB/s]"}},"5c490849ea384dfe8d3c9651b1b7a0f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c250e0f70a1b49e3b05b1db9e75d422a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91483c64ef844402bc7b7d97c1989f22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7496a6a38df447469802185c0aed7f80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb7f8898dd74d9ba4a237e385f99bdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7439bd51a5546389fb55dc3c6537946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ad25fd1e4e849198f4dac8bf3f87efd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ab7ea552844657b7a5083ccf99139b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49210d3ee9d3494d94d2cb5d28594486","IPY_MODEL_ab1d4aff729c4db28f7309c53c0de157","IPY_MODEL_efc5afb3bef94a01ad1c8ba6b9ac4eed"],"layout":"IPY_MODEL_8993bc5eb2fb4293a8bd27b3ac49c82d"}},"49210d3ee9d3494d94d2cb5d28594486":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5698537832ac4d77856519666d9eadea","placeholder":"​","style":"IPY_MODEL_35cfc65801a04df3845bf4b894085baa","value":"Downloading: 100%"}},"ab1d4aff729c4db28f7309c53c0de157":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7490f1a811724ec4bf8085896eec5c65","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b99184549f65427fac1ef7d4e5bc50ca","value":289}},"efc5afb3bef94a01ad1c8ba6b9ac4eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcbf80ae4374428abf4fa83bcc652be8","placeholder":"​","style":"IPY_MODEL_f8486688d5974f4a8c873aad4056afa6","value":" 289/289 [00:00&lt;00:00, 7.72kB/s]"}},"8993bc5eb2fb4293a8bd27b3ac49c82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5698537832ac4d77856519666d9eadea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35cfc65801a04df3845bf4b894085baa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7490f1a811724ec4bf8085896eec5c65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99184549f65427fac1ef7d4e5bc50ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dcbf80ae4374428abf4fa83bcc652be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8486688d5974f4a8c873aad4056afa6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a11e7de3894e4c84a38a7bb51a0cf9c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19b3f2fc6c4547de8e9b15e32761453f","IPY_MODEL_3573c8c2348f4c2c96071a16b0d629fa","IPY_MODEL_1e94399593464ba79d0a286f0da9d7b3"],"layout":"IPY_MODEL_f0ee73bd8b154d56b604e77c0a84d3da"}},"19b3f2fc6c4547de8e9b15e32761453f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ab094fbd0c4ecb9e47606d5afd0346","placeholder":"​","style":"IPY_MODEL_b669050fc39e48ffbe7d7661139e1fd7","value":"Downloading: 100%"}},"3573c8c2348f4c2c96071a16b0d629fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fc4505367b84ffabd4af12508c55deb","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7612eae596a0443682c4b0856dcd4823","value":425}},"1e94399593464ba79d0a286f0da9d7b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_651cea257f494d98812b3aeec8425b89","placeholder":"​","style":"IPY_MODEL_87b13dc7f26d4366a03cd44ed5ce0bba","value":" 425/425 [00:00&lt;00:00, 10.9kB/s]"}},"f0ee73bd8b154d56b604e77c0a84d3da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ab094fbd0c4ecb9e47606d5afd0346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b669050fc39e48ffbe7d7661139e1fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fc4505367b84ffabd4af12508c55deb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7612eae596a0443682c4b0856dcd4823":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"651cea257f494d98812b3aeec8425b89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87b13dc7f26d4366a03cd44ed5ce0bba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37a668c29667400aabe2aaf65876a612":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e458d56fbfe7409c9d2dc6ebbab4f40a","IPY_MODEL_2caff93ce43f41d58f5c035be02e2fef","IPY_MODEL_82d112ec515a4fc79d23f712e5bb68a5"],"layout":"IPY_MODEL_5132c6702862499d9bf81741c9d31839"}},"e458d56fbfe7409c9d2dc6ebbab4f40a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8237c8a0e124775a91de8caf25251f3","placeholder":"​","style":"IPY_MODEL_b40af997745c4d809e1e856bf1508a01","value":"Downloading: 100%"}},"2caff93ce43f41d58f5c035be02e2fef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1f6485880744099bf40a9a8be7a6a9","max":445025130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03eb745c5e2a438ea87851863c2c2b56","value":445025130}},"82d112ec515a4fc79d23f712e5bb68a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_552aaeabb3cb4ef7ba66664dd23590a5","placeholder":"​","style":"IPY_MODEL_30e3050518a0455ca8fded0e43df3356","value":" 424M/424M [00:12&lt;00:00, 37.0MB/s]"}},"5132c6702862499d9bf81741c9d31839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8237c8a0e124775a91de8caf25251f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b40af997745c4d809e1e856bf1508a01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e1f6485880744099bf40a9a8be7a6a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03eb745c5e2a438ea87851863c2c2b56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"552aaeabb3cb4ef7ba66664dd23590a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e3050518a0455ca8fded0e43df3356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}